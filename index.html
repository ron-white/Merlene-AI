<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MERLENE AI Assistant</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div class="mic-btn-container">
        <button class="mic-btn" id="micBtn" title="Activate Microphone">
            <span id="micIcon">ðŸŽ¤</span>
        </button>
        <div class="speech-text" id="speechText"></div>
    </div>
    <script>
        // Microphone button logic
        const micBtn = document.getElementById('micBtn');
        const speechText = document.getElementById('speechText');
        const micIcon = document.getElementById('micIcon');
        let listening = false;

        // Speech recognition setup
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = true;

        recognition.onstart = function () {
            listening = true;
            micBtn.classList.add('active');
            micIcon.textContent = 'ðŸ”´';
            speechText.textContent = 'Listening...';
        };
        recognition.onend = function () {
            listening = false;
            micBtn.classList.remove('active');
            micIcon.textContent = 'ðŸŽ¤';
        };
        recognition.onresult = function (event) {
            let transcript = '';
            for (let i = event.resultIndex; i < event.results.length; ++i) {
                transcript += event.results[i][0].transcript;
            }
            speechText.textContent = transcript;
            if (event.results[event.results.length - 1].isFinal) {
                window.speechSynthesis.cancel();
                takeCommand(transcript.toLowerCase());
            }
        };

        micBtn.onclick = function () {
            if (!listening) {
                recognition.start();
            } else {
                recognition.stop();
            }
        };

        // AI response will be spoken and displayed
        function speak(text) {
            speechText.textContent = text;
            const text_speak = new SpeechSynthesisUtterance(text);
            text_speak.rate = 1;
            text_speak.volume = 1;
            text_speak.pitch = 1;
            window.speechSynthesis.speak(text_speak);
        }
        // ...existing JS logic for takeCommand, etc. can be included here...
    </script>
</body>

</html>
